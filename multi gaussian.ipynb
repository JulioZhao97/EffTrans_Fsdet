{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b12bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dim=1024\n",
    "mean = [0 for i in range(dim)]\n",
    "cov = [[0 for i in range(dim)] for i in range(dim)]\n",
    "for i in range(dim):\n",
    "    cov[i][i] = 1\n",
    "    \n",
    "data = np.random.multivariate_normal(mean, cov, 1000)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493f06fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 780)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.99, whiten=True)\n",
    "data = pca.fit_transform(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7164c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n_components = np.arange(1, 50, 1)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0)\n",
    "          for n in n_components]\n",
    "aics = [model.fit(data).aic(data) for model in models]\n",
    "plt.plot(n_components, aics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289dfae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixturdigits_new = pca.inverse_transform(data_new)e(5, covariance_type='full', random_state=0)\n",
    "gmm.fit(data)\n",
    "print(gmm.converged_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0f9955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 780)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "data_new = gmm.sample(n_samples=100)\n",
    "print(data_new[0].shape)\n",
    "print(data_new[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8f8324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GaussianMixture in module sklearn.mixture._gaussian_mixture:\n",
      "\n",
      "class GaussianMixture(sklearn.mixture._base.BaseMixture)\n",
      " |  GaussianMixture(n_components=1, *, covariance_type='full', tol=0.001, reg_covar=1e-06, max_iter=100, n_init=1, init_params='kmeans', weights_init=None, means_init=None, precisions_init=None, random_state=None, warm_start=False, verbose=0, verbose_interval=10)\n",
      " |  \n",
      " |  Gaussian Mixture.\n",
      " |  \n",
      " |  Representation of a Gaussian mixture model probability distribution.\n",
      " |  This class allows to estimate the parameters of a Gaussian mixture\n",
      " |  distribution.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gmm>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int, default=1\n",
      " |      The number of mixture components.\n",
      " |  \n",
      " |  covariance_type : {'full', 'tied', 'diag', 'spherical'}, default='full'\n",
      " |      String describing the type of covariance parameters to use.\n",
      " |      Must be one of:\n",
      " |  \n",
      " |      - 'full': each component has its own general covariance matrix.\n",
      " |      - 'tied': all components share the same general covariance matrix.\n",
      " |      - 'diag': each component has its own diagonal covariance matrix.\n",
      " |      - 'spherical': each component has its own single variance.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      The convergence threshold. EM iterations will stop when the\n",
      " |      lower bound average gain is below this threshold.\n",
      " |  \n",
      " |  reg_covar : float, default=1e-6\n",
      " |      Non-negative regularization added to the diagonal of covariance.\n",
      " |      Allows to assure that the covariance matrices are all positive.\n",
      " |  \n",
      " |  max_iter : int, default=100\n",
      " |      The number of EM iterations to perform.\n",
      " |  \n",
      " |  n_init : int, default=1\n",
      " |      The number of initializations to perform. The best results are kept.\n",
      " |  \n",
      " |  init_params : {'kmeans', 'random'}, default='kmeans'\n",
      " |      The method used to initialize the weights, the means and the\n",
      " |      precisions.\n",
      " |      Must be one of::\n",
      " |  \n",
      " |          'kmeans' : responsibilities are initialized using kmeans.\n",
      " |          'random' : responsibilities are initialized randomly.\n",
      " |  \n",
      " |  weights_init : array-like of shape (n_components, ), default=None\n",
      " |      The user-provided initial weights.\n",
      " |      If it is None, weights are initialized using the `init_params` method.\n",
      " |  \n",
      " |  means_init : array-like of shape (n_components, n_features), default=None\n",
      " |      The user-provided initial means,\n",
      " |      If it is None, means are initialized using the `init_params` method.\n",
      " |  \n",
      " |  precisions_init : array-like, default=None\n",
      " |      The user-provided initial precisions (inverse of the covariance\n",
      " |      matrices).\n",
      " |      If it is None, precisions are initialized using the 'init_params'\n",
      " |      method.\n",
      " |      The shape depends on 'covariance_type'::\n",
      " |  \n",
      " |          (n_components,)                        if 'spherical',\n",
      " |          (n_features, n_features)               if 'tied',\n",
      " |          (n_components, n_features)             if 'diag',\n",
      " |          (n_components, n_features, n_features) if 'full'\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given to the method chosen to initialize the\n",
      " |      parameters (see `init_params`).\n",
      " |      In addition, it controls the generation of random samples from the\n",
      " |      fitted distribution (see the method `sample`).\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      If 'warm_start' is True, the solution of the last fitting is used as\n",
      " |      initialization for the next call of fit(). This can speed up\n",
      " |      convergence when fit is called several times on similar problems.\n",
      " |      In that case, 'n_init' is ignored and only a single initialization\n",
      " |      occurs upon the first call.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. If 1 then it prints the current\n",
      " |      initialization and each iteration step. If greater than 1 then\n",
      " |      it prints also the log probability and the time needed\n",
      " |      for each step.\n",
      " |  \n",
      " |  verbose_interval : int, default=10\n",
      " |      Number of iteration done before the next print.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights_ : array-like of shape (n_components,)\n",
      " |      The weights of each mixture components.\n",
      " |  \n",
      " |  means_ : array-like of shape (n_components, n_features)\n",
      " |      The mean of each mixture component.\n",
      " |  \n",
      " |  covariances_ : array-like\n",
      " |      The covariance of each mixture component.\n",
      " |      The shape depends on `covariance_type`::\n",
      " |  \n",
      " |          (n_components,)                        if 'spherical',\n",
      " |          (n_features, n_features)               if 'tied',\n",
      " |          (n_components, n_features)             if 'diag',\n",
      " |          (n_components, n_features, n_features) if 'full'\n",
      " |  \n",
      " |  precisions_ : array-like\n",
      " |      The precision matrices for each component in the mixture. A precision\n",
      " |      matrix is the inverse of a covariance matrix. A covariance matrix is\n",
      " |      symmetric positive definite so the mixture of Gaussian can be\n",
      " |      equivalently parameterized by the precision matrices. Storing the\n",
      " |      precision matrices instead of the covariance matrices makes it more\n",
      " |      efficient to compute the log-likelihood of new samples at test time.\n",
      " |      The shape depends on `covariance_type`::\n",
      " |  \n",
      " |          (n_components,)                        if 'spherical',\n",
      " |          (n_features, n_features)               if 'tied',\n",
      " |          (n_components, n_features)             if 'diag',\n",
      " |          (n_components, n_features, n_features) if 'full'\n",
      " |  \n",
      " |  precisions_cholesky_ : array-like\n",
      " |      The cholesky decomposition of the precision matrices of each mixture\n",
      " |      component. A precision matrix is the inverse of a covariance matrix.\n",
      " |      A covariance matrix is symmetric positive definite so the mixture of\n",
      " |      Gaussian can be equivalently parameterized by the precision matrices.\n",
      " |      Storing the precision matrices instead of the covariance matrices makes\n",
      " |      it more efficient to compute the log-likelihood of new samples at test\n",
      " |      time. The shape depends on `covariance_type`::\n",
      " |  \n",
      " |          (n_components,)                        if 'spherical',\n",
      " |          (n_features, n_features)               if 'tied',\n",
      " |          (n_components, n_features)             if 'diag',\n",
      " |          (n_components, n_features, n_features) if 'full'\n",
      " |  \n",
      " |  converged_ : bool\n",
      " |      True when convergence was reached in fit(), False otherwise.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of step used by the best fit of EM to reach the convergence.\n",
      " |  \n",
      " |  lower_bound_ : float\n",
      " |      Lower bound value on the log-likelihood (of the training data with\n",
      " |      respect to the model) of the best fit of EM.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  BayesianGaussianMixture : Gaussian mixture model fit with a variational\n",
      " |      inference.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.mixture import GaussianMixture\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n",
      " |  >>> gm = GaussianMixture(n_components=2, random_state=0).fit(X)\n",
      " |  >>> gm.means_\n",
      " |  array([[10.,  2.],\n",
      " |         [ 1.,  2.]])\n",
      " |  >>> gm.predict([[0, 0], [12, 3]])\n",
      " |  array([1, 0])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GaussianMixture\n",
      " |      sklearn.mixture._base.BaseMixture\n",
      " |      sklearn.base.DensityMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=1, *, covariance_type='full', tol=0.001, reg_covar=1e-06, max_iter=100, n_init=1, init_params='kmeans', weights_init=None, means_init=None, precisions_init=None, random_state=None, warm_start=False, verbose=0, verbose_interval=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  aic(self, X)\n",
      " |      Akaike information criterion for the current model on the input X.\n",
      " |      \n",
      " |      You can refer to this :ref:`mathematical section <aic_bic>` for more\n",
      " |      details regarding the formulation of the AIC used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape (n_samples, n_dimensions)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aic : float\n",
      " |          The lower the better.\n",
      " |  \n",
      " |  bic(self, X)\n",
      " |      Bayesian information criterion for the current model on the input X.\n",
      " |      \n",
      " |      You can refer to this :ref:`mathematical section <aic_bic>` for more\n",
      " |      details regarding the formulation of the BIC used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape (n_samples, n_dimensions)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bic : float\n",
      " |          The lower the better.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.mixture._base.BaseMixture:\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Estimate model parameters with the EM algorithm.\n",
      " |      \n",
      " |      The method fits the model ``n_init`` times and sets the parameters with\n",
      " |      which the model has the largest likelihood or lower bound. Within each\n",
      " |      trial, the method iterates between E-step and M-step for ``max_iter``\n",
      " |      times until the change of likelihood or lower bound is less than\n",
      " |      ``tol``, otherwise, a ``ConvergenceWarning`` is raised.\n",
      " |      If ``warm_start`` is ``True``, then ``n_init`` is ignored and a single\n",
      " |      initialization is performed upon the first call. Upon consecutive\n",
      " |      calls, training starts where it left off.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present for API consistency by convention.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The fitted mixture.\n",
      " |  \n",
      " |  fit_predict(self, X, y=None)\n",
      " |      Estimate model parameters using X and predict the labels for X.\n",
      " |      \n",
      " |      The method fits the model n_init times and sets the parameters with\n",
      " |      which the model has the largest likelihood or lower bound. Within each\n",
      " |      trial, the method iterates between E-step and M-step for `max_iter`\n",
      " |      times until the change of likelihood or lower bound is less than\n",
      " |      `tol`, otherwise, a :class:`~sklearn.exceptions.ConvergenceWarning` is\n",
      " |      raised. After fitting, it predicts the most probable label for the\n",
      " |      input data points.\n",
      " |      \n",
      " |      .. versionadded:: 0.20\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present for API consistency by convention.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape (n_samples,)\n",
      " |          Component labels.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the labels for the data samples in X using trained model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape (n_samples,)\n",
      " |          Component labels.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Evaluate the components' density for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      resp : array, shape (n_samples, n_components)\n",
      " |          Density of each Gaussian component for each sample in X.\n",
      " |  \n",
      " |  sample(self, n_samples=1)\n",
      " |      Generate random samples from the fitted Gaussian distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n_samples : int, default=1\n",
      " |          Number of samples to generate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array, shape (n_samples, n_features)\n",
      " |          Randomly generated sample.\n",
      " |      \n",
      " |      y : array, shape (nsamples,)\n",
      " |          Component labels.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Compute the per-sample average log-likelihood of the given data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_dimensions)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present for API consistency by convention.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_likelihood : float\n",
      " |          Log-likelihood of `X` under the Gaussian mixture model.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Compute the log-likelihood of each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_prob : array, shape (n_samples,)\n",
      " |          Log-likelihood of each sample in `X` under the current model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.DensityMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GaussianMixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "665baab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1024,) and (780,1024) not aligned: 1024 (dim 0) != 780 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14909/3588024446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmfewshot/lib/python3.7/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 np.dot(\n\u001b[1;32m    150\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 )\n\u001b[1;32m    153\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1024,) and (780,1024) not aligned: 1024 (dim 0) != 780 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(data_new[0].shape)\n",
    "data_new = pca.inverse_transform(data_new[0])\n",
    "print(data_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd4126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
